{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 트랜스포머로 만드는 대화형 챗봇\n",
    "\n",
    "## 평가 루브릭\n",
    "\n",
    "아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
    "\n",
    "평가문항\t상세기준\n",
    "1. 한국어 전처리를 통해 학습 데이터셋을 구축하였다. : 공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.\n",
    "2. 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다. : 구현한 트랜스포머 모델이 한국어 병렬 데이터 학습시 안정적으로 수렴하였다.\n",
    "3. 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다. : 한국어 입력문장에 그럴듯한 한국어로 답변을 리턴하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로젝트: 한국어 데이터로 챗봇 만들기\n",
    "영어로 만들었던 챗봇을 한국어 데이터로 바꿔서 훈련시켜봅시다.\n",
    "\n",
    "## Step 1. 데이터 수집하기\n",
    "한국어 챗봇 데이터는 송영숙님이 공개한 챗봇 데이터를 사용합니다.\n",
    "\n",
    "이 데이터는 아래의 링크에서 다운로드 할 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-28 12:46:19--  https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.76.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.76.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 889842 (869K) [text/plain]\n",
      "Saving to: ‘ChatbotData .csv.2’\n",
      "\n",
      "ChatbotData .csv.2  100%[===================>] 868.99K  2.29MB/s    in 0.4s    \n",
      "\n",
      "2020-10-28 12:46:19 (2.29 MB/s) - ‘ChatbotData .csv.2’ saved [889842/889842]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7380</th>\n",
       "      <td>이런경우.답은 나온거 같은데.</td>\n",
       "      <td>고민하고 있다면 그게 맞을거예요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3067</th>\n",
       "      <td>언젠가는 나를 좋아해 주는 사람 있겠지?</td>\n",
       "      <td>저도 좋아해요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855</th>\n",
       "      <td>우리 사랑이었을까?</td>\n",
       "      <td>사랑이 있으면 헤어짐도 있는거예요. 헤어졌다고 사랑이 아닌게 되지는 않아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>꿈속에서도 안보여</td>\n",
       "      <td>진짜 잊으세요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4238</th>\n",
       "      <td>주택 청약 가입</td>\n",
       "      <td>내 집 마련의 한 걸음을 내딛으셨네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11598</th>\n",
       "      <td>짝사랑 하던 사람한테 고백했는데 차임. 계속 좋아해도 될까.</td>\n",
       "      <td>좋아하는 건 본인의 자유지만 많이 힘들 거예요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7411</th>\n",
       "      <td>이별 6개월째네</td>\n",
       "      <td>이젠 좀 괜찮아졌길 바랍니다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9362</th>\n",
       "      <td>남자친구가 첫사랑이야</td>\n",
       "      <td>마지막 사랑이 되길 바랍니다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4786</th>\n",
       "      <td>키 왜 안 크지</td>\n",
       "      <td>신경쓰면 스트레스 받아요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6582</th>\n",
       "      <td>사랑.이별.추억.미련</td>\n",
       "      <td>사랑의 잔해들.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Q  \\\n",
       "7380                    이런경우.답은 나온거 같은데.   \n",
       "3067              언젠가는 나를 좋아해 주는 사람 있겠지?   \n",
       "10855                         우리 사랑이었을까?   \n",
       "5725                           꿈속에서도 안보여   \n",
       "4238                            주택 청약 가입   \n",
       "11598  짝사랑 하던 사람한테 고백했는데 차임. 계속 좋아해도 될까.   \n",
       "7411                            이별 6개월째네   \n",
       "9362                         남자친구가 첫사랑이야   \n",
       "4786                            키 왜 안 크지   \n",
       "6582                         사랑.이별.추억.미련   \n",
       "\n",
       "                                                A  label  \n",
       "7380                           고민하고 있다면 그게 맞을거예요.      1  \n",
       "3067                                     저도 좋아해요.      0  \n",
       "10855  사랑이 있으면 헤어짐도 있는거예요. 헤어졌다고 사랑이 아닌게 되지는 않아요.      2  \n",
       "5725                                     진짜 잊으세요.      1  \n",
       "4238                        내 집 마련의 한 걸음을 내딛으셨네요.      0  \n",
       "11598                  좋아하는 건 본인의 자유지만 많이 힘들 거예요.      2  \n",
       "7411                             이젠 좀 괜찮아졌길 바랍니다.      1  \n",
       "9362                             마지막 사랑이 되길 바랍니다.      2  \n",
       "4786                               신경쓰면 스트레스 받아요.      0  \n",
       "6582                                     사랑의 잔해들.      1  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ChatbotData .csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 전처리하기\n",
    "영어 데이터와는 전혀 다른 데이터인만큼 영어 데이터에 사용했던 전처리와 일부 동일한 전처리도 필요하겠지만 전체적으로는 다른 전처리를 수행해야 할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "    # student와 온점 사이에 거리를 만듭니다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\", ㄱ-ㅎ, ㅏ-ㅣ)를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"[^ㄱ-ㅣ가-힣a-zA-Z0-9?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'저는 에이펠 , aiffel 에서 수업을 듣고 있는 학생 입니다 .'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_sentence(\"저는 에이펠, AIFFEL 에서 수업을 듣고 있는 '학생'입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['12시 땡!', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', ..., '흑기사 해주는 짝남.',\n",
       "        '힘든 연애 좋은 연애라는게 무슨 차이일까?', '힘들어서 결혼할까봐'], dtype=object),\n",
       " 11823)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = df.Q.values\n",
    "questions, len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['하루가 또 가네요.', '위로해 드립니다.', '여행은 언제나 좋죠.', ..., '설렜겠어요.',\n",
       "        '잘 헤어질 수 있는 사이 여부인 거 같아요.', '도피성 결혼은 하지 않길 바라요.'], dtype=object),\n",
       " 11823)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = df.A.values\n",
    "answers, len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = list(map(preprocess_sentence, questions))\n",
    "answers = list(map(preprocess_sentence, answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'ppl 심하네'],\n",
       " ['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .'])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[:5], answers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. SubwordTextEncoder 사용하기\n",
    "한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야한다고 많은 분들이 알고있습니다. 하지만 여기서는 형태소 분석기가 아닌 위 실습에서 사용했던 내부 단어 토크나이저인 SubwordTextEncoder를 그대로 사용해보세요.\n",
    "\n",
    "### 병렬 데이터 전처리하기\n",
    "질문과 답변의 셋을 각각 questions와 answers에 저장하였으므로, 본격적으로 전처리를 진행해보겠습니다. 이번 스텝에서 진행할 전체적인 과정을 요약하면 다음과 같습니다.\n",
    "\n",
    "TensorFlow Datasets SubwordTextEncoder를 토크나이저로 사용한다.  단어 보다 더 작은 단위인 Subword를 기준으로 토크나이징하고,  각 토큰을 고유한 정수로 인코딩한다.\n",
    "각 문장을 토큰화하고 각 문장의 시작과 끝을 나타내는 START_TOKEN 및 END_TOKEN을 추가한다.\n",
    "최대 길이 MAX_LENGTH인 40을 넘는 문장들은 필터링한다.\n",
    "MAX_LENGTH보다 길이가 짧은 문장들은 40에 맞도록 패딩한다.\n",
    "### 1. 단어장(Vocabulary) 만들기\n",
    "우선 각 단어에 고유한 정수 인덱스를 부여하기 위해서 단어장(Vocabulary)을 만들어보겠습니다. 단어장을 만들 때에는 질문과 답변 데이터셋을 모두 사용하여 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8170]\n",
      "END_TOKEN의 번호 : [8171]\n"
     ]
    }
   ],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8172\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 각 단어를 고유한 정수로 인코딩(Integer encoding) & 패딩(Padding)\n",
    "tfds.features.text.SubwordTextEncoder를 사용해서 tokenizer를 정의하고 Vocabulary를 만들었다면, tokenizer.encode()로 각 단어를 정수로 변환할 수 있고 또는 tokenizer.decode()를 통해 정수 시퀀스를 단어 시퀀스로 변환할 수 있습니다.\n",
    "\n",
    "예를 들어서 22번째 샘플을 tokenizer.encode()의 입력으로 사용해서 변환 결과를 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이.\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "    \n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        # 최대 길이 40이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "\n",
    "    # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8172\n",
      "필터링 후의 샘플 개수: 11823\n",
      "필터링 후의 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 교사 강요(Teacher Forcing) 사용하기\n",
    "tf.data.Dataset API는 훈련 프로세스의 속도가 빨라지도록 입력 파이프라인을 구축하는 API입니다.\n",
    "\n",
    "이를 적극 사용하기 위해서 질문과 답변의 쌍을 tf.data.Dataset의 입력으로 넣어주는 작업을 합니다.\n",
    "\n",
    "이때, 디코더의 입력과 실제값(레이블)을 정의해주기 위해서는 교사 강요(Teacher Forcing)이라는 언어 모델의 훈련 기법을 이해해야만 합니다. \n",
    "\n",
    "이전 자신의 출력이 현재 자신의 상태를 결정하는 모델을 자기회귀 모델(auto-regressive model, AR)이라고 합니다. 앞서 교사 강요를 이해하기 위해 읽었던 글에 등장한 RNN 언어 모델은 대표적인 자기 회귀 모델의 예이며, 트랜스포머의 디코더 또한 자기회귀 모델입니다.\n",
    "\n",
    "트랜스포머 디코더에서도 교사 강요(Teacher Forcing)를 적용합니다.\n",
    "\n",
    "질문과 답변의 쌍을 tf.data.Dataset API의 입력으로 사용하여 파이프라인을 구성합니다. 이때, 교사 강요를 위해서 answers[:, :-1]를 디코더의 입력값, answers[:, 1:]를 디코더의 레이블로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. 모델 구성하기\n",
    "위 실습 내용을 참고하여 트랜스포머 모델을 구현합니다.\n",
    "\n",
    "### 모델 정의 및 학습하기\n",
    "이제 앞서 사용한 인코더의 층 함수와 디코더의 층 함수를 사용하여 트랜스포머 함수를 정의합니다.\n",
    "\n",
    "### 1. 포지셔널 인코딩 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        \n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 스케일드 닷 프로덕트 어텐션 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    \n",
    "    \"\"\"어텐션 가중치를 계산. \"\"\"\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # add the mask to zero out padding tokens\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 멀티헤드 어텐션 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # linear layers\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다.\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷-프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다.\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # final linear layer\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 크리에이트 패딩 마스크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 1. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 크리에이트 룩어해드 마스크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[1. 1. 1. 1. 1.]\n",
      "   [1. 0. 1. 1. 1.]\n",
      "   [1. 0. 0. 1. 1.]\n",
      "   [1. 0. 0. 0. 1.]\n",
      "   [1. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[0, 5, 1, 5, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 인코더 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "          })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 디코더 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': look_ahead_mask\n",
    "        })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1,\n",
    "            'key': enc_outputs,\n",
    "            'value': enc_outputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 트랜스포머"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크하기위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 두번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "      # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "      )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 모델 생성\n",
    "num_layers, d-Model, units는 전부 사용자가 정할 수 있는 하이퍼파라미터값입니다.\n",
    "\n",
    "논문에서의 구현 그래도 진행해 봅니다.\n",
    "- num_layers는 6\n",
    "- d-Model은 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 512)    10496000    inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 512)    14702592    dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8172)   4192236     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 29,390,828\n",
      "Trainable params: 29,390,828\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 4 # 인코더와 디코더의 층의 개수 (학습 속도 때문에 4로 조정함)\n",
    "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원 (논문 그대로 구현)\n",
    "NUM_HEADS = 16 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 손실 함수(Loss function)\n",
    "레이블인 시퀀스에 패딩이 되어져 있으므로, loss를 계산할 때 패딩 마스크를 적용해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 커스텀된 학습률(Learning rate)\n",
    "딥러닝 모델학습시 learning rate는 매우 중요한 하이퍼파라미터입니다. 최근에는 모델학습 초기에 learning rate를 급격히 높였다가, 이후 train step이 진행됨에 따라 서서히 낮추어 가면서 안정적으로 수렴하게 하는 고급 기법을 널리 사용하고 있습니다. 이런 방법을 커스텀 학습률 스케줄링(Custom Learning rate Scheduling)이라고 합니다.\n",
    "\n",
    "논문에 나온 공식을 참고하여 커스텀 학습률 스케줄러를 통한 아담 옵티마이저를 사용합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "방금 정의한 커스텀 학습률 스케줄링 계획을 시각화해 봅시다. 학습 초기에는 learning_rate가 step_num에 비례해서 증가하다가 이후로는 감소하는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 모델 컴파일\n",
    "손실 함수와 커스텀 된 학습률(learning rate)를 사용하여 모델을 컴파일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 훈련하기\n",
    "총 100 에포크를 학습합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "185/185 [==============================] - 29s 157ms/step - loss: 1.3409 - accuracy: 0.0302\n",
      "Epoch 2/100\n",
      "185/185 [==============================] - 29s 154ms/step - loss: 1.0643 - accuracy: 0.0497\n",
      "Epoch 3/100\n",
      "185/185 [==============================] - 28s 152ms/step - loss: 0.9698 - accuracy: 0.0520\n",
      "Epoch 4/100\n",
      "185/185 [==============================] - 28s 153ms/step - loss: 0.9149 - accuracy: 0.0552\n",
      "Epoch 5/100\n",
      "185/185 [==============================] - 28s 153ms/step - loss: 0.8583 - accuracy: 0.0586\n",
      "Epoch 6/100\n",
      "185/185 [==============================] - 28s 151ms/step - loss: 0.7924 - accuracy: 0.0634\n",
      "Epoch 7/100\n",
      "185/185 [==============================] - 28s 150ms/step - loss: 0.7193 - accuracy: 0.0700\n",
      "Epoch 8/100\n",
      "185/185 [==============================] - 28s 149ms/step - loss: 0.6406 - accuracy: 0.0788\n",
      "Epoch 9/100\n",
      "185/185 [==============================] - 27s 147ms/step - loss: 0.5577 - accuracy: 0.0885\n",
      "Epoch 10/100\n",
      "185/185 [==============================] - 27s 143ms/step - loss: 0.4745 - accuracy: 0.0993\n",
      "Epoch 11/100\n",
      "185/185 [==============================] - 27s 148ms/step - loss: 0.3960 - accuracy: 0.1098\n",
      "Epoch 12/100\n",
      "185/185 [==============================] - 28s 152ms/step - loss: 0.3201 - accuracy: 0.1201\n",
      "Epoch 13/100\n",
      "185/185 [==============================] - 29s 156ms/step - loss: 0.2567 - accuracy: 0.1283\n",
      "Epoch 14/100\n",
      "185/185 [==============================] - 28s 153ms/step - loss: 0.2013 - accuracy: 0.1371\n",
      "Epoch 15/100\n",
      "185/185 [==============================] - 28s 151ms/step - loss: 0.1583 - accuracy: 0.1441\n",
      "Epoch 16/100\n",
      "185/185 [==============================] - 31s 168ms/step - loss: 0.1258 - accuracy: 0.1490\n",
      "Epoch 17/100\n",
      "185/185 [==============================] - 28s 153ms/step - loss: 0.1034 - accuracy: 0.1529\n",
      "Epoch 18/100\n",
      "185/185 [==============================] - 27s 148ms/step - loss: 0.0897 - accuracy: 0.1549\n",
      "Epoch 19/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0797 - accuracy: 0.1564\n",
      "Epoch 20/100\n",
      "185/185 [==============================] - 28s 149ms/step - loss: 0.0759 - accuracy: 0.1570\n",
      "Epoch 21/100\n",
      "185/185 [==============================] - 28s 149ms/step - loss: 0.0722 - accuracy: 0.1575\n",
      "Epoch 22/100\n",
      "185/185 [==============================] - 27s 148ms/step - loss: 0.0715 - accuracy: 0.1573\n",
      "Epoch 23/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0637 - accuracy: 0.1590\n",
      "Epoch 24/100\n",
      "185/185 [==============================] - 27s 145ms/step - loss: 0.0565 - accuracy: 0.1606\n",
      "Epoch 25/100\n",
      "185/185 [==============================] - 27s 145ms/step - loss: 0.0502 - accuracy: 0.1622\n",
      "Epoch 26/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0455 - accuracy: 0.1634\n",
      "Epoch 27/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0403 - accuracy: 0.1647\n",
      "Epoch 28/100\n",
      "185/185 [==============================] - 27s 145ms/step - loss: 0.0370 - accuracy: 0.1655\n",
      "Epoch 29/100\n",
      "185/185 [==============================] - 27s 145ms/step - loss: 0.0348 - accuracy: 0.1662\n",
      "Epoch 30/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0305 - accuracy: 0.1672\n",
      "Epoch 31/100\n",
      "185/185 [==============================] - 27s 146ms/step - loss: 0.0288 - accuracy: 0.1677\n",
      "Epoch 32/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0265 - accuracy: 0.1682\n",
      "Epoch 33/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0247 - accuracy: 0.1688\n",
      "Epoch 34/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0230 - accuracy: 0.1691\n",
      "Epoch 35/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0215 - accuracy: 0.1695\n",
      "Epoch 36/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0202 - accuracy: 0.1699\n",
      "Epoch 37/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0184 - accuracy: 0.1704\n",
      "Epoch 38/100\n",
      "185/185 [==============================] - 27s 145ms/step - loss: 0.0173 - accuracy: 0.1708\n",
      "Epoch 39/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0166 - accuracy: 0.1709\n",
      "Epoch 40/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0161 - accuracy: 0.1710\n",
      "Epoch 41/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0155 - accuracy: 0.1711\n",
      "Epoch 42/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0145 - accuracy: 0.1713\n",
      "Epoch 43/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0136 - accuracy: 0.1717\n",
      "Epoch 44/100\n",
      "185/185 [==============================] - 27s 145ms/step - loss: 0.0129 - accuracy: 0.1717\n",
      "Epoch 45/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0123 - accuracy: 0.1720\n",
      "Epoch 46/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0115 - accuracy: 0.1721\n",
      "Epoch 47/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0112 - accuracy: 0.1722\n",
      "Epoch 48/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0108 - accuracy: 0.1724\n",
      "Epoch 49/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0106 - accuracy: 0.1724\n",
      "Epoch 50/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0101 - accuracy: 0.1726\n",
      "Epoch 51/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0098 - accuracy: 0.1726\n",
      "Epoch 52/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0092 - accuracy: 0.1728\n",
      "Epoch 53/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0091 - accuracy: 0.1728\n",
      "Epoch 54/100\n",
      "185/185 [==============================] - 28s 150ms/step - loss: 0.0085 - accuracy: 0.1730\n",
      "Epoch 55/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0085 - accuracy: 0.1730\n",
      "Epoch 56/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0083 - accuracy: 0.1730\n",
      "Epoch 57/100\n",
      "185/185 [==============================] - 27s 143ms/step - loss: 0.0074 - accuracy: 0.1732\n",
      "Epoch 58/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0079 - accuracy: 0.1731\n",
      "Epoch 59/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0071 - accuracy: 0.1733\n",
      "Epoch 60/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0071 - accuracy: 0.1733\n",
      "Epoch 61/100\n",
      "185/185 [==============================] - 27s 143ms/step - loss: 0.0074 - accuracy: 0.1733\n",
      "Epoch 62/100\n",
      "185/185 [==============================] - 27s 143ms/step - loss: 0.0067 - accuracy: 0.1734\n",
      "Epoch 63/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0069 - accuracy: 0.1733\n",
      "Epoch 64/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0067 - accuracy: 0.1734\n",
      "Epoch 65/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0062 - accuracy: 0.1735\n",
      "Epoch 66/100\n",
      "185/185 [==============================] - 27s 147ms/step - loss: 0.0063 - accuracy: 0.1735\n",
      "Epoch 67/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0064 - accuracy: 0.1735\n",
      "Epoch 68/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0064 - accuracy: 0.1735\n",
      "Epoch 69/100\n",
      "185/185 [==============================] - 27s 147ms/step - loss: 0.0055 - accuracy: 0.1737\n",
      "Epoch 70/100\n",
      "185/185 [==============================] - 27s 145ms/step - loss: 0.0057 - accuracy: 0.1737\n",
      "Epoch 71/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0055 - accuracy: 0.1737\n",
      "Epoch 72/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0053 - accuracy: 0.1738\n",
      "Epoch 73/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0050 - accuracy: 0.1738\n",
      "Epoch 74/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0049 - accuracy: 0.1738\n",
      "Epoch 75/100\n",
      "185/185 [==============================] - 27s 143ms/step - loss: 0.0051 - accuracy: 0.1737\n",
      "Epoch 76/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0048 - accuracy: 0.1738\n",
      "Epoch 77/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0048 - accuracy: 0.1739\n",
      "Epoch 78/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0045 - accuracy: 0.1739\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0044 - accuracy: 0.1740\n",
      "Epoch 80/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0045 - accuracy: 0.1739\n",
      "Epoch 81/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0048 - accuracy: 0.1738\n",
      "Epoch 82/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0043 - accuracy: 0.1740\n",
      "Epoch 83/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0039 - accuracy: 0.1741\n",
      "Epoch 84/100\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0042 - accuracy: 0.1740\n",
      "Epoch 85/100\n",
      "185/185 [==============================] - 26s 142ms/step - loss: 0.0042 - accuracy: 0.1739\n",
      "Epoch 86/100\n",
      "185/185 [==============================] - 26s 141ms/step - loss: 0.0040 - accuracy: 0.1740\n",
      "Epoch 87/100\n",
      "185/185 [==============================] - 26s 142ms/step - loss: 0.0038 - accuracy: 0.1740\n",
      "Epoch 88/100\n",
      "185/185 [==============================] - 26s 141ms/step - loss: 0.0039 - accuracy: 0.1740\n",
      "Epoch 89/100\n",
      "185/185 [==============================] - 26s 141ms/step - loss: 0.0039 - accuracy: 0.1740\n",
      "Epoch 90/100\n",
      "185/185 [==============================] - 26s 141ms/step - loss: 0.0038 - accuracy: 0.1740\n",
      "Epoch 91/100\n",
      "185/185 [==============================] - 26s 141ms/step - loss: 0.0038 - accuracy: 0.1740\n",
      "Epoch 92/100\n",
      "185/185 [==============================] - 26s 141ms/step - loss: 0.0037 - accuracy: 0.1740\n",
      "Epoch 93/100\n",
      "185/185 [==============================] - 26s 141ms/step - loss: 0.0036 - accuracy: 0.1741\n",
      "Epoch 94/100\n",
      "185/185 [==============================] - 26s 141ms/step - loss: 0.0034 - accuracy: 0.1741\n",
      "Epoch 95/100\n",
      "185/185 [==============================] - 26s 141ms/step - loss: 0.0035 - accuracy: 0.1741\n",
      "Epoch 96/100\n",
      "185/185 [==============================] - 26s 142ms/step - loss: 0.0035 - accuracy: 0.1741\n",
      "Epoch 97/100\n",
      "185/185 [==============================] - 26s 141ms/step - loss: 0.0034 - accuracy: 0.1741\n",
      "Epoch 98/100\n",
      "185/185 [==============================] - 26s 141ms/step - loss: 0.0033 - accuracy: 0.1741\n",
      "Epoch 99/100\n",
      "185/185 [==============================] - 26s 141ms/step - loss: 0.0032 - accuracy: 0.1742\n",
      "Epoch 100/100\n",
      "185/185 [==============================] - 26s 141ms/step - loss: 0.0033 - accuracy: 0.1741\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 학습결과 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(121)\n",
    "plt.title('accuracy')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.legend(['accuracy'], loc='best')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.legend(['loss'], loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 챗봇 테스트하기\n",
    "예측(inference) 단계는 기본적으로 다음과 같은 과정을 거칩니다.\n",
    "\n",
    "1. 새로운 입력 문장에 대해서는 훈련때와 동일한 전처리를 거친다.\n",
    "2. 입력 문장을 토크나이징하고, START_TOKEN과 END_TOKEN을 추가한다.\n",
    "3. 패딩 마스킹과 룩 어헤드 마스킹을 계산한다.\n",
    "4. 디코더는 입력 시퀀스로부터 다음 단어를 예측한다.\n",
    "5. 디코더는 예측된 다음 단어를 기존의 입력 시퀀스에 추가하여 새로운 입력으로 사용한다.\n",
    "6. END_TOKEN이 예측되거나 문장의 최대 길이에 도달하면 디코더는 동작을 멈춘다.\n",
    "\n",
    "위의 과정을 모두 담은 decoder_inference() 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞 뒤로 추가.\n",
    "    # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없으므로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임의의 입력 문장에 대해서 decoder_inference() 함수를 호출하여 챗봇의 대답을 얻는 sentence_generation() 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해서 디코더를 동작시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임의의 문장으로부터 챗봇의 대답을 얻어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너는 앞으로 뭐가 되고 싶니?\n",
      "출력 : 혼자 준비하기는 조금 벅찰텐대요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'혼자 준비하기는 조금 벅찰텐대요 .'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('너는 앞으로 뭐가 되고 싶니?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너의 이상형은 누구니?\n",
      "출력 : 저는 위로해드리는 로봇이에요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저는 위로해드리는 로봇이에요 .'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"너의 이상형은 누구니?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 지구에 나를 좋아하는 사람이 몇명이나 있을까?\n",
      "출력 : 좋은 선택은 아니에요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 선택은 아니에요 .'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"지구에 나를 좋아하는 사람이 몇명이나 있을까?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 누군가를 진심으로 사랑하나요?\n",
      "출력 : 너무 예쁜 것 같아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'너무 예쁜 것 같아요 .'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"누군가를 진심으로 사랑하나요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 언제 화가 나나요?\n",
      "출력 : 너무 무리하지 마세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'너무 무리하지 마세요 .'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"언제 화가 나나요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. 모델 평가하기\n",
    "Step 1에서 선택한 전처리 방법을 고려하여 입력된 문장에 대해서 대답을 얻는 예측 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Accuracy가 17.8 밖에 되지 않는데도 불구하고,\n",
    "* 학습하지 않은 문장에 대해서도 매우 그럴 듯 하게 답변을 주는 것을 알 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
